sentence1 = "The magnificent castle stood tall on top of the hill, its grandeur captivating anyone who laid eyes upon it, while the sun cast a golden glow over the surrounding landscape," + \
            "painting a picturesque scene that seemed to come straight out of a fairytale."
sentence2 = "The cat chased the mouse around the house, causing quite a commotion."


#natural language processing (NLP) tasks.
#splitting text into individual words or sentences (known as tokens)
import nltk #toolkit
nltk.download('punkt')

from nltk import word_tokenize, sent_tokenize

print('Tokenized words:', word_tokenize(sentence1))
print('\nTokenized sentences:', sent_tokenize(sentence1))

import nltk
nltk.download('averaged_perceptron_tagger')

# split the sentences into individual words or tokens. 
from nltk import pos_taga
token = word_tokenize(sentence1) + word_tokenize(sentence2)
#takes the list of tokens as input and assigns a POS tag to each word based on its #grammatical category.
tagged = pos_tag(token) #parts of speech                
print("Tagging Parts of Speech:", tagged)


import nltk
nltk.download('stopwords')

from nltk.corpus import stopwords

#(the", "is", "a") that are often removed from text 
stop_words = stopwords.words('english')

# producing a list of individual words called token
token = word_tokenize(sentence1)
#store the words that are not stopwords.
cleaned_token = []

for word in token:
    if word not in stop_words:
        cleaned_token.append(word)

print('Unclean version:', token)
print('\nCleaned version:', cleaned_token)


from nltk.stem import PorterStemmer

stemmer = PorterStemmer()

token = word_tokenize(sentence2)

#Finally, the stemmed words are joined back into a sentence using the " #".join(stemmed) expression, and the resulting stemmed sentence is printed.
stemmed = [stemmer.stem(word) for word in token]
print(" ".join(stemmed))
